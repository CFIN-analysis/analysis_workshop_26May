{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Nick7900/glhmm_protocols/blob/main/Procedures/Procedure_2_Across_trials_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpcaRpm0wZYB"
   },
   "source": [
    "# GLHMM Workshop - Introductory module\n",
    "\n",
    "This notebook is meant as a guide and example of instantiating and training a TDE-HMM and visualising its output. The notebook is based on one of the [available tutorials](https://nbviewer.org/github/vidaurre/glhmm/blob/main/docs/notebooks/HMM-TDE_vs_HMM-MAR_example.ipynb) in the GLHMM toolbox.\n",
    "\n",
    "The notebook sketches a hypothetical neuroscience project, with the aim to find common networks across participants in resting state whole-brain MEG data.\n",
    "\n",
    "This notebook is scheduled as follows:\n",
    "\n",
    "0. [PREPARATION](#preparation)\n",
    "1. [Download data](#download)\n",
    "2. [Basic data preprocessing](#preprocess)\n",
    "3. [Instantiate TDE-HMM](#HMM_instantiate)\n",
    "4. [Train HMM](#HMM_train)  -  here you will have the option to load a trained HMM, and go directly to the plotting section.\n",
    "5. [Basic sanity checks and summary metrics](#sanity_checks)\n",
    "6. [States spectral analysis](#spectral)\n",
    "\n",
    "*The GLHMM workshop organising team*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKHeyOzlwZZo"
   },
   "source": [
    "## 0. PREPARATION <a id=\"preparation\"></a>\n",
    "\n",
    "If you dont have the **GLHMM-package** installed, or if you have not yet installed it using **Google Colab**, then run the following command in your terminal:\n",
    "\n",
    "```pip install git+https://github.com/vidaurre/glhmm```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DeM4mM2VsVuK",
    "outputId": "a3d8105d-83c5-41de-e081-e952025777c7"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/vidaurre/glhmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwhi8VU3wZuj"
   },
   "source": [
    "#### Import necessary packages\n",
    "\n",
    "In order to be able to run this notebook, you will also need some other packages. Please install them via pip install (follow syntax in previous cell) if the next cell does not run successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrcgXaY64Fa0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glhmm import glhmm, preproc, utils, graphics, spectral, io, statistics, auxiliary\n",
    "import pickle\n",
    "import pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYkzO_XpE4VD"
   },
   "source": [
    "## 1. Download data <a id=\"download\"></a>\n",
    "\n",
    "The next two cells will fetch the data from the OSF website and download them into a new folder called \"example_data\" in the same folder as this notebook. If you prefer, you can create the folder and download the files from the [OSF project page](https://osf.io/8qcyj/?view_only=119c38072a724e0091db5ba377935666) and skip the next two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "hpT6-pTF4Fd4",
    "outputId": "7e2961ee-de13-48fc-8fe7-67d43712ba30"
   },
   "outputs": [],
   "source": [
    "def install(package):\n",
    "    pip.main(['install', package])\n",
    "\n",
    "try:\n",
    "    import osfclient\n",
    "except ImportError:\n",
    "    print('osfclient is not installed, installing it now')\n",
    "    install('osfclient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHB2BYeS4FmC",
    "outputId": "a2621a4e-edb3-4f33-afd5-cf02c55fdbdf"
   },
   "outputs": [],
   "source": [
    "! osf -p 8qcyj fetch MEG_data/data_MEG_TDE.pkl ./example_data/data_MEG_TDE.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i_x1QXPFPoY"
   },
   "source": [
    "### Load data in memory\n",
    "\n",
    "We will now load the data in memory.\n",
    "\n",
    "***This step is compulsory, whether you downloaded the data manually or running the previous two cells.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xh10xW93GH_h",
    "outputId": "0d68998c-ef59-49bf-dec1-53b24551d0cd"
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "\n",
    "with open(\"./example_data/data_MEG_TDE.pkl\", \"rb\") as f:\n",
    "    data_meg_tde = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pGGxZn1FPwu"
   },
   "source": [
    "### Data information\n",
    "\n",
    "The data we just loaded are whole-brain MEG resting state data. The data were collected from participants while resting in a dark room. Each participant completed two sessions, except for one participant with just one session.\n",
    "\n",
    "Each session is stored as a 2D matrix with the shape of (No. of timepoints, No. of parcels):\n",
    "\n",
    "- Timepoints: The total number of recorded time points in the session.\n",
    "- Parcels: Here regions according to a prespecified parcellation.\n",
    "\n",
    "These data are a subset of a dataset collected and used for the original [TDE-HMM paper](https://www.nature.com/articles/s41467-018-05316-z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dNYnd96NLJpP",
    "outputId": "5d17aa29-e54c-4eaf-ec11-53f6cfe64e21"
   },
   "outputs": [],
   "source": [
    "# Display data information\n",
    "print(\"Number of sessions in data_meg: %d\"%len(data_meg_tde))\n",
    "print(\"Shape of each session: \")\n",
    "for i in range(len(data_meg_tde)):\n",
    "  print(data_meg_tde[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhznJqLPFP3w"
   },
   "source": [
    "### Prepare data in HMM-friendly format\n",
    "\n",
    "We now need to make the data in the right format for the HMM, meaning concatenate all sessions and subjects along the time axis. We also need to create the indices that will indicate the start and end timepoint of each session:\n",
    "\n",
    "- **Concatenated brain activity (X_concat)**:\n",
    "The brain activity data (data_meg) contains recordings from multiple sessions. We concatenate all the sessions along the time dimension to form a single, continuous 2D matrix: [timepoints Ã— sessions, features].\n",
    "\n",
    "- **Create index matrix (idx_data)**:\n",
    "To track the start and end timepoints for each session, we generate an index matrix, idx_data, using the function get_indices_from_list. It will have a shape of: [No. of sessions, 2]. Each row specifies the start and end timepoints for a session.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAGJAxTULsol"
   },
   "outputs": [],
   "source": [
    "X_concat = np.concatenate(data_meg_tde,axis=0)\n",
    "\n",
    "# Get the start and end indices for each session\n",
    "idx_data = statistics.get_indices_from_list(data_meg_tde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3VGW-uHLzMW",
    "outputId": "65fd5da5-7da3-4c1f-943e-e16ae8065d52"
   },
   "outputs": [],
   "source": [
    "# show the length of the data\n",
    "print('total length of data:')\n",
    "print(len(X_concat))\n",
    "\n",
    "# show indices\n",
    "print('indices:')\n",
    "print(idx_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlqH1PJrFP-V"
   },
   "source": [
    "## 2. Basic data preprocessing <a id=\"preprocess\"></a>\n",
    "\n",
    "We always recommend to plot the data before doing any preprocessing, and understand what preprocessing steps might be appropriate. \n",
    "\n",
    "Check the [documentation](https://glhmm.readthedocs.io/en/latest/preproc.html) for the various preprocessing options in our toolbox.\n",
    "\n",
    "***The data for this tutorial have already been preprocessed, so we will only standardise them.***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiSriX89LzTs"
   },
   "outputs": [],
   "source": [
    "# Preprocess data - we will only use the default option, which is to standardise the data\n",
    "X_preproc, _, log = preproc.preprocess_data(X_concat, idx_data, standardise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "KwDpA7B9NYyG",
    "outputId": "428bf077-8152-42ef-e7fd-e7584aff3b90"
   },
   "outputs": [],
   "source": [
    "# visualize some data\n",
    "# decide on a plotting range of the signal - this is arbitrary\n",
    "plot_range = np.arange(100000,101000)\n",
    "\n",
    "Fs = 250 # sampling frequency of the signal\n",
    "n_regions = X_preproc.shape[1]\n",
    "\n",
    "# plot each parcel separately\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "for i in range(n_regions):\n",
    "    plt.plot(X_preproc[plot_range,i]+i*5)\n",
    "\n",
    "plt.xticks(np.arange(0,len(plot_range)+1,Fs),np.arange(int(len(plot_range)/Fs+1)))\n",
    "plt.xlabel('time [s]')\n",
    "plt.yticks(np.arange(0,n_regions*5,5),np.arange(n_regions))\n",
    "plt.ylabel('parcel')\n",
    "plt.title('Example of Preprocessed Signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTTTUyyWbH4J"
   },
   "source": [
    "\n",
    "## TDE-HMM\n",
    "\n",
    "The TDE-HMM was introduced in [Vidaurre et al. (2018)](https://www.nature.com/articles/s41467-018-05316-z). This HMM models the autocovariance of the signal. Given a multichannel time series data *y*, the autocovariance is computed within a window of length 2L and resolution S around each time point *yt*. The window is specified by the user in the form of **lags** = (-L, -L+S, ...-S, 0, S, ..., L-S, L), indicating the time points around t to be included in the window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBsvy-DrOVo4"
   },
   "source": [
    "## 3. Instantiate a TDE-HMM  <a id=\"HMM_instantiate\"></a>\n",
    "To run a TDE-HMM in with the GLHMM package, the data are first restructured (embedded) according to the **lags**, and then a Gaussian HMM is run on the embedded data. Here, the states are the covariance matrices that best describe the signal.  \n",
    "\n",
    "1. **Embed data**: For the first step, we will use the `build_data_tde` option in the preprocessing module. This will create an embedded version of the data according to the **lags** we define. In this specific case, our window of lags will be of length 2L, where L=35, with resolution S=5. We will then use PCA on the embedded signal, using number of PC = number of parcels * 2, to follow the original [TDE-HMM paper](https://doi.org/10.1038/s41467-018-05316-z) preprocessing and HMM settings.\n",
    "\n",
    "2. **Initialise HMM**: We then initialise the glhmm object, which we here call `TDE_hmm`. By specifying the parameters of the glhmm object, we define which type of model we want to fit and how states should be defined. We will model 10 states by setting the parameter `K=10`. We will also specify the covariance type as `covtype='full'` and no means modelling. So our states will be characterised only by functional connectivity (covariance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tbyKpf3M88h"
   },
   "outputs": [],
   "source": [
    "# Specify time lags\n",
    "S=5\n",
    "L = 35\n",
    "lags = np.arange(-L, L + 1, S)\n",
    "\n",
    "# Build the MEG data in TDE format\n",
    "X_embedded, idx_tde, pca_model = preproc.build_data_tde(X_preproc,idx_data,lags=lags,pca=n_regions*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRvurW7DM_F_"
   },
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "K=10\n",
    "TDE_hmm = glhmm.glhmm(model_beta='no', model_mean='state', K=K, covtype='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVRnTLPcRtnP"
   },
   "source": [
    "## 4. Train a TDE-HMM <a id=\"HMM_train\"></a>\n",
    "\n",
    "We will now train the TDE-HMM. The training procedure will output the state time courses (Gammas), the joint probability of past and future states conditioned on the data (Xi) and the free energy computed at each iteration of the process (FE).\n",
    "\n",
    "We will also get the Viterbi path (vpath, a categorical version of the Gammas).\n",
    "\n",
    "\n",
    "***This step can take several minutes, up to an hour. If you want to avoid training the HMM yourself and want to go directly to the visualization part, you can skip this part and download the trained model and its output from the OSF project page. Simply run the next two cells.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbiQOeD6Rsn-",
    "outputId": "dccd77ce-5a43-4105-8624-6856dc81aa75"
   },
   "outputs": [],
   "source": [
    "# download trained model\n",
    "! osf -p 8qcyj fetch MEG_data/hmm_tde.pkl ./example_data/hmm_tde.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CXK_8e1U6Qj",
    "outputId": "03b39b96-2664-44e2-b09d-d9b9c0390701"
   },
   "outputs": [],
   "source": [
    "# load into the notebook\n",
    "with open('./example_data/hmm_tde.pkl', \"rb\") as f:\n",
    "    hmm_dict = pickle.load(f)\n",
    "\n",
    "TDE_hmm = hmm_dict['hmm']\n",
    "Gamma = hmm_dict['stc']\n",
    "vpath = hmm_dict['vpath']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAZ18nl_VCxT"
   },
   "source": [
    "***For those of you who have time and want to train the HMM, run the next cell instead!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fiSLrkqiRs-G"
   },
   "outputs": [],
   "source": [
    "# or train the HMM from scratch\n",
    "print('Training HMM-TDE')\n",
    "options={'gpu_acceleration':2}\n",
    "Gamma, Xi, FE = TDE_hmm.train(X=None, Y=X_embedded, indices=idx_tde, options=options)\n",
    "vpath = TDE_hmm.decode(X=None, Y=X_embedded, viterbi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBz_RllGUfHw"
   },
   "outputs": [],
   "source": [
    "# save your trained hmm\n",
    "hmm_dict = {'hmm':TDE_hmm,'stc':Gamma,'xi':Xi,'fe':FE,'vpath':vpath}\n",
    "with open(\"./example_data/hmm_tde.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(hmm_dict, fp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDtV6eAfXIU8"
   },
   "source": [
    "### Padding Viterbi path and Gamma\n",
    "\n",
    "Because of the delay-embeddings, the state time courses are now shorter than the original data. To be able to plot the signal with the Viterbi path, we need a padding operation to fill in the missing values of the HMM output. \n",
    "\n",
    "This is done with the function `padGamma()` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91pHnf1TUfKh"
   },
   "outputs": [],
   "source": [
    "T = auxiliary.get_T(idx_data)\n",
    "options_tde = {'embeddedlags':list(lags)}\n",
    "paddedVP = auxiliary.padGamma(vpath, T, options_tde)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9q7tPM0KWCXk"
   },
   "source": [
    "## 5. Basic sanity checks and summary metrics <a id=\"sanity_checks\"></a>\n",
    "\n",
    "We will now perform some basic sanity checks and plot summary metrics. These include:\n",
    "\n",
    "*   Plot example of Viterbi path with signal\n",
    "*   Plot states fractional occupancy (FO)\n",
    "*   Plot states switching rate (SR)\n",
    "*   Plot states lifetimes (LT)\n",
    "*   Plot states probabilities, mean and covariance\n",
    "\n",
    "We will use the appropriate functions in the GLHMM `graphics` module to plot all these metrics. Check the [documentation](https://glhmm.readthedocs.io/en/latest/graphics.html) to see all our graphics options.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "8IjySiN0UfM3",
    "outputId": "1444111e-39ef-4e25-c126-7fd567316230"
   },
   "outputs": [],
   "source": [
    "# plot state Viterbi path with signal\n",
    "# define a plotting range\n",
    "plotting_range = np.arange(15000,20000)\n",
    "\n",
    "# use the appropriate function in the graphic package\n",
    "graphics.plot_vpath(paddedVP[plotting_range], signal=X_preproc[plotting_range,1].copy(), title=\"States and signal example\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R94lbiMZX3nJ"
   },
   "outputs": [],
   "source": [
    "# inspect states - basic sanity checks\n",
    "# Get summary metrics\n",
    "FO = utils.get_FO(Gamma, indices=idx_tde)\n",
    "SR = utils.get_switching_rate(Gamma, indices=idx_tde)\n",
    "LTmean, LTmed, LTmax = utils.get_life_times(vpath, indices=idx_tde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "A6htGg-GMe8O",
    "outputId": "d8eabedd-a36a-474a-9c09-6f0db088acd7"
   },
   "outputs": [],
   "source": [
    "# plot some relevant statistics\n",
    "graphics.plot_FO(FO,width=0.8, figsize=(7,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "Jiwfrd59Mgen",
    "outputId": "9d00d727-1dfd-427c-fc74-9076c2cb2b8c"
   },
   "outputs": [],
   "source": [
    "graphics.plot_switching_rates(SR,width=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "wJw0L0zrMpcO",
    "outputId": "0e2b914f-0062-46e0-ba2c-2a941d6b78a7"
   },
   "outputs": [],
   "source": [
    "graphics.plot_state_lifetimes(LTmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "82pUi2eGYqwL",
    "outputId": "7f6d908c-bfe2-4481-ff55-9f106b88b38f"
   },
   "outputs": [],
   "source": [
    "# inspect states\n",
    "# plot probabilities, mean and covariance\n",
    "graphics.plot_state_prob_and_covariance(TDE_hmm.Pi,TDE_hmm.P, TDE_hmm.get_means(),TDE_hmm.get_covariance_matrices(), figsize=(8,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYvsVoBabXBa"
   },
   "source": [
    "## 6. States spectral analysis <a id=\"spectral\"></a>\n",
    "\n",
    "We will now use the `spectral` package in GLHMM to compute the states power spectra and coherence, and plot them.\n",
    "\n",
    "This is done with the function `multitaper_spectral_analysis()` that computes the states power spectra using the nonparametric multitaper approach.\n",
    "\n",
    "To compute the power spectra, you need to specify the sampling frequency, Fs, of the data. In this case, `Fs=250`.\n",
    "\n",
    "The function also needs the Gamma (i.e., the state probability time courses) to compute the power spectrum of each state. We can input the padded Gamma, or the original gamma, specifying in the options the `embeddedlags` used to train the HMM. In this last case, the function will pad the Gamma first.\n",
    "\n",
    "You can also specify in the options for the spectral analysis `fpass`, the frequency range for the power spectrum estimation.\n",
    "\n",
    "Check the [documentation](https://glhmm.readthedocs.io/en/latest/spectral.html) on how to specify more options for the multitaper spectral analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3tUbuABY_Kb",
    "outputId": "4395d0b0-135e-45dd-9f4b-4299abe0f382"
   },
   "outputs": [],
   "source": [
    "# get states spectral properties\n",
    "options = {'embeddedlags':list(lags), 'fpass':[0,100]}\n",
    "spectral_measures = spectral.multitaper_spectral_analysis(X_preproc, idx_data, Fs=250, Gamma=Gamma, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wIimAW7eP5M"
   },
   "source": [
    "The output of the `multitaper_spectral_analysis` function is a dictionary containing:\n",
    "- 'f' : the frequency bins\n",
    "- 'p' : the power spectrum of each state, per subject/session and per channel\n",
    "- 'psdc' : the cross-channel power spectrum, per subject/session and per state\n",
    "- 'coh' : the cross-channel coherence, per subject/session and per state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5DVgqdic_Fn"
   },
   "source": [
    "We will then use the functions in the `graphics` module to visualise the states spectra, with and without the option of hichlighting the standard frequency bands.\n",
    "\n",
    "We will visualise them for one session and for two randomly selected channels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "zC4uUTMgcuk6",
    "outputId": "e4a5dbe8-e2a4-4ff8-cdf8-91886daefee3"
   },
   "outputs": [],
   "source": [
    "# plot the state power spectra for a specific session, and channel\n",
    "\n",
    "selected_channel = 4\n",
    "selected_session = 2\n",
    "\n",
    "f = spectral_measures['f']\n",
    "psd = spectral_measures['p']\n",
    "\n",
    "graphics.plot_state_psd(psd[selected_session,:,selected_channel],\n",
    "                        f,\n",
    "                        highlight_freq=True,\n",
    "                        title=\"States power spectra in channel %d\"%selected_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "Sr9fEQ_mgfiu",
    "outputId": "7e6fe800-ddee-4662-aefd-1d7c2ace24ab"
   },
   "outputs": [],
   "source": [
    "# plot the state power spectra for a specific session, and channel\n",
    "\n",
    "selected_channel = 21\n",
    "selected_session = 2\n",
    "\n",
    "f = spectral_measures['f']\n",
    "psd = spectral_measures['p']\n",
    "\n",
    "graphics.plot_state_psd(psd[selected_session,:,selected_channel],\n",
    "                        f,\n",
    "                        highlight_freq=True,\n",
    "                        title=\"States power spectra in channel %d\"%selected_channel,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lFiYjuVg0bi"
   },
   "source": [
    "We will then visualise the states cross-channels cohrence, for one session and between two randomly selected channels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "JoxfVfare0lX",
    "outputId": "dd94b730-fb8d-47a9-a045-c8d50f9523b8"
   },
   "outputs": [],
   "source": [
    "# for a specific session, plot the state coherence between two channels\n",
    "coh = spectral_measures['coh']\n",
    "chann_1 = 30\n",
    "chann_2 = 3\n",
    "graphics.plot_state_coherence(coh[selected_session,:,chann_1,chann_2],\n",
    "                              f,\n",
    "                              title='Coherence between regions %d and %d'%(chann_1,chann_2),\n",
    "                              #highlight_freq=True,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-axXd6QwkCo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
